{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5f040c9b-c49f-492a-b493-e3937d1fe38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import xesmf\n",
    "# https://github.com/raphaeldussin/HCtFlood\n",
    "from HCtFlood import kara as flood\n",
    "import sys\n",
    "import numpy as np\n",
    "import xarray\n",
    "import os.path\n",
    "\n",
    "era5_dict = {'ERA5_2m_temperature':'t2m',\n",
    "             'ERA5_sea_ice_cover':'siconc',\n",
    "             'ERA5_10m_u_component_of_wind':'u10',\n",
    "             'ERA5_sea_surface_temperature':'sst',\n",
    "             'ERA5_10m_v_component_of_wind':'v10',\n",
    "             'ERA5_surface_solar_radiation_downwards':'ssrd',\n",
    "             'ERA5_surface_thermal_radiation_downwards':'strd',\n",
    "            'ERA5_total_rain_rate':'trr',\n",
    "             'ERA5_mean_sea_level_pressure':'msl',\n",
    "             'ERA5_2m_specific_humidity':'huss'}\n",
    "\n",
    "def interp_landmask(landmask_file):\n",
    "    landmask = xr.open_dataset(landmask_file).rename({'x': 'lon', 'y': 'lat'})\n",
    "    lon_centers = landmask['lon'].values\n",
    "    lat_centers = landmask['lat'].values\n",
    "    lon_corners = 0.25 * (\n",
    "        lon_centers[:-1, :-1]\n",
    "        + lon_centers[1:, :-1]\n",
    "        + lon_centers[:-1, 1:]\n",
    "        + lon_centers[1:, 1:]\n",
    "    )\n",
    "    # have to add 2 extra rows/columns to the array becuase we remove 1 when we calculate the corners from the center values\n",
    "    lon_corners_exp = np.full((lon_corners.shape[0]+2,lon_corners.shape[1]+2),np.nan)\n",
    "    lon_corners_exp[:-2,:-2] = lon_corners\n",
    "    landmask['lon_b'] = xr.DataArray(data=lon_corners_exp, dims=(\"nyp\", \"nxp\"))\n",
    "    lon_b = landmask['lon_b']\n",
    "    filled = lon_b.interpolate_na(dim='nyp',method='linear',fill_value=\"extrapolate\")\n",
    "    filled_lon = filled.interpolate_na(dim='nxp',method='linear',fill_value=\"extrapolate\")\n",
    "    \n",
    "    # interpolate latitidue corners from latitude cell centers\n",
    "    lat_corners = 0.25 * (\n",
    "        lat_centers[:-1, :-1]\n",
    "        + lat_centers[1:, :-1]\n",
    "        + lat_centers[:-1, 1:]\n",
    "        + lat_centers[1:, 1:]\n",
    "    )\n",
    "\n",
    "    # create expanded latitude corners array and then interpolate the values so our nxp, nyp = nx+1, ny+1\n",
    "    lat_corners_exp = np.full((lat_corners.shape[0]+2,lat_corners.shape[1]+2),np.nan)\n",
    "    lat_corners_exp[:-2,:-2] = lat_corners\n",
    "    landmask['lat_b'] = xr.DataArray(data=lat_corners_exp, dims=(\"nyp\", \"nxp\"))\n",
    "    lat_b = landmask['lat_b']\n",
    "    filled= lat_b.interpolate_na(dim='nyp',method='linear',fill_value=\"extrapolate\")\n",
    "    filled_lat = filled.interpolate_na(dim='nxp',method='linear',fill_value=\"extrapolate\")\n",
    "    landmask['lon_b'] = filled_lon\n",
    "    landmask['lat_b'] = filled_lat\n",
    "    landmask['mask'] = landmask['mask'].where(landmask['mask'] != 1)\n",
    "    \n",
    "    return landmask\n",
    "    \n",
    "    \n",
    "def interp_era5(era5_file, era5_var):\n",
    "    era = xr.open_dataset(era5_file)\n",
    "    era = era.rename({'longitude': 'lon', 'latitude': 'lat'})\n",
    "    if \"lon\" in era.coords:\n",
    "        era = era.assign_coords(lon=(np.where(era['lon'].values > 180., era['lon'].values - 360, era['lon'].values)))\n",
    "        era = era.swap_dims({'lon' : 'nx'})    \n",
    "        era = era.swap_dims({'lat' : 'ny'}) \n",
    "    if \"lon\" in era.data_vars:\n",
    "        era['lon'].values =  np.where(era['lon'].values > 180., era['lon'].values - 360, era['lon'].values)\n",
    "\n",
    "    lon_centers = era['lon'].values\n",
    "    lat_centers = era['lat'].values\n",
    "    # To use conservative regidding, we need the cells corners. \n",
    "    # Since they are not provided, we are creating some using a crude approximation. \n",
    "    lon_corners = 0.25 * (\n",
    "        lon_centers[:-1]\n",
    "        + lon_centers[1:]\n",
    "        + lon_centers[:-1]\n",
    "        + lon_centers[1:]\n",
    "    )\n",
    "\n",
    "    lat_corners = 0.25 * (\n",
    "        lat_centers[:-1]\n",
    "        + lat_centers[1:]\n",
    "        + lat_centers[:-1]\n",
    "        + lat_centers[1:]\n",
    "    )\n",
    "\n",
    "    # trim down era by 1 cell\n",
    "    era = era.isel(nx=slice(1,-1), ny=slice(1,-1))\n",
    "    da_era_var=era[era5_var].values\n",
    "    \n",
    "    # add nxp and nyp dimensions for the lat/lon corners to latch onto\n",
    "    era = era.expand_dims({'nyp':(len(era.lat) + 1)})\n",
    "    era = era.expand_dims({'nxp':(len(era.lon) + 1)})\n",
    "\n",
    "    # add the lat/lon corners as data variables,\n",
    "    era['lat_corners'] = xr.DataArray(data=lat_corners, dims=(\"nyp\"))\n",
    "    era['lon_corners'] = xr.DataArray(data=lon_corners, dims=(\"nxp\"))\n",
    "    # drop the variable\n",
    "    era = era.drop_vars(era5_var)\n",
    "    era[era5_var] = xr.DataArray(data=da_era_var, dims=(\"time\" ,\"lat\", \"lon\"))\n",
    "    \n",
    "    # create meshgrids for center and corner points so we can co-locate with landmask meshgrids.\n",
    "    lon2d, lat2d = np.meshgrid(era.lon.values, era.lat.values)\n",
    "    lon2d_b, lat2d_b = np.meshgrid(era.lon_corners.values, era.lat_corners.values)\n",
    "    \n",
    "    # assign coordinates now that we have our corner points\n",
    "    era = era.assign_coords({\"lon\" : ((\"ny\", \"nx\"), lon2d)})\n",
    "    era = era.assign_coords({\"lat\" : ((\"ny\", \"nx\"), lat2d)})\n",
    "    era = era.assign_coords({\"lon_b\" : ((\"nyp\", \"nxp\"), lon2d_b)})\n",
    "    era = era.assign_coords({\"lat_b\" : ((\"nyp\", \"nxp\"), lat2d_b)})\n",
    "    \n",
    "    return era\n",
    "\n",
    "def flood_era5_data(era5_file,era5_var,landmask_file, outfile, reuse_weights=False):\n",
    " # interp landmask\n",
    "    landmask = interp_landmask(landmask_file)\n",
    "\n",
    "    #interp era\n",
    "    era = interp_era5(era5_file, era5_var)\n",
    "    \n",
    "    # regrid conservatively: conservative does the best, especially along fine points\n",
    "    regrid_domain = xesmf.Regridder(landmask, era, 'conservative', \n",
    "                                    periodic=False, reuse_weights=reuse_weights, filename='regrid_domain.nc')\n",
    "    land_regrid = regrid_domain(landmask.mask)\n",
    "    land_regrid=land_regrid.expand_dims(time=era['time'])\n",
    "    land_regrid=land_regrid.transpose(\"time\", \"ny\", \"nx\")\n",
    "    #print(land_regrid)\n",
    "    era=era.transpose(\"time\", \"lat\", \"lon\", \"ny\", \"nx\", \"nyp\", \"nxp\")\n",
    "    # cut era based on regridded landmask\n",
    "    era_cut = era[era5_var].where(land_regrid.values == 0)\n",
    "\n",
    "    # flood our cut out points\n",
    "    flooded = flood.flood_kara(era_cut)\n",
    "    flooded = flooded.isel(z=0).drop('z')\n",
    "    #print(flooded)\n",
    "    # note that this current version of this code will cut down your era5 domain by 2 rows/colse)\n",
    "    era = xr.open_dataset(era5_file)\n",
    "    era = era.isel(longitude=slice(1,len(era.longitude)-1), latitude=slice(1,len(era.latitude)-1))\n",
    "    era=era.transpose(\"time\", \"latitude\", \"longitude\")\n",
    "    \n",
    "    era[era5_var].values = flooded.values    \n",
    "    \n",
    "    if era5_var=='ssrd' or era5_var=='strd':\n",
    "        # convert radiation from J/m2 to W/m2: https://confluence.ecmwf.int/pages/viewpage.action?pageId=155337784\n",
    "        era[era5_var].values = era[era5_var].values/3600\n",
    "        era[era5_var].attrs['units'] = 'W m-2'\n",
    "    if era5_var=='huss':\n",
    "        era[era5_var].attrs['dtype'] = 'float64'\n",
    "        era[era5_var].attrs['standard_name'] = 'specific_humidity'\n",
    "        era[era5_var].attrs['long_name'] = 'Near-Surface Specific Humidity'\n",
    "        era[era5_var].attrs['coordinates'] = 'height'\n",
    "        era[era5_var].attrs['units'] = '1'\n",
    "        era['height'] = 2.0\n",
    "        era['height'].attrs['units'] = \"m\"\n",
    "        era['height'].attrs['axis'] = \"Z\"\n",
    "        era['height'].attrs['positive'] = \"up\"\n",
    "        era['height'].attrs['long_name'] = \"height\"\n",
    "        era['height'].attrs['standard_name'] = \"height\"\n",
    "    era.to_netcdf(outfile,format='NETCDF4_CLASSIC', unlimited_dims='time')\n",
    "    era.close()\n",
    "\n",
    "\n",
    "def main():\n",
    "    landmask_file = '/home/james/gridInfo/nwa25/land_mask.nc'\n",
    "    padded_dir = '/Volumes/A1/workdir/james/nwa25_input/forcing/setup/padded/'\n",
    "    flood_dir = '/Volumes/A1/workdir/james/nwa25_input/forcing/ERA5_final/'\n",
    "    era5_year = 1996\n",
    "    keys_list=list(era5_dict)\n",
    "    \n",
    "    for f in era5_dict.keys():\n",
    "        reuse_weights=False\n",
    "        era5_file = f\"{padded_dir}/{f}_{era5_year}.nc\"\n",
    "        outfile = f\"{flood_dir}/{f}_{era5_year}.nc\"\n",
    "        if f != keys_list[0]:\n",
    "            reuse_weights=True\n",
    "        \n",
    "        if os.path.isfile(outfile) == False:\n",
    "            print(f)\n",
    "            flood_era5_data(era5_file=era5_file, era5_var=era5_dict[f],reuse_weights=reuse_weights,landmask_file=landmask_file,outfile=outfile)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
